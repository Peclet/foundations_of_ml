{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with varying covariance $\\Sigma_1 \\neq \\Sigma_2 \\neq \\Sigma_3 ... \\neq \\Sigma_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To reset the printoptions\n",
    "# np.set_printoptions(edgeitems=3,infstr='inf',linewidth=75, nanstr='nan', precision=8,suppress=False, threshold=1000, formatter=None)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "#np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For multi-class label y ={0, 1, 2, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "#y=(y>0).astype(int) \n",
    "\n",
    "target_names = list(dataset.target_names)\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (38, 4), (112,), (38,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscAnalysis: \n",
    "    def compute_phi(self, y):\n",
    "        n = len(y)\n",
    "        phi = dict()\n",
    "        for idx in range(len(self.classes)):\n",
    "            phi[idx] = (1/n) * np.sum(y==idx)\n",
    "        return phi\n",
    "    \n",
    "    def compute_mu(self, X, y):\n",
    "        mu_dict = dict()\n",
    "        for idx in range(len(self.classes)):\n",
    "            # Add mu for each class\n",
    "            mu_dict[idx] = np.sum(X[y==idx], axis=0)/ np.sum(y==idx)\n",
    "        return mu_dict\n",
    "\n",
    "    def compute_sigma(self, X, y):\n",
    "        sigma_dict = dict()\n",
    "        #n = len(X)\n",
    "        #y = y.reshape(-1,1)\n",
    "        Xmu = X.copy()\n",
    "        for idx in range(len(self.classes)):\n",
    "            n = np.sum(y==idx)\n",
    "            Xmu_i = Xmu[y==idx] - self.mu[idx]\n",
    "            sigma = (1/n) * Xmu_i.T@Xmu_i\n",
    "            sigma_dict[idx] = sigma\n",
    "        return sigma_dict\n",
    "    \n",
    "    \n",
    "    def compute_Pxyi(self, X, idx):\n",
    "        \"\"\"Probability of X given y\"\"\"\n",
    "        m = X.shape[1]\n",
    "        sigma_inv = np.linalg.inv(self.sigma[idx])\n",
    "        det_sigma = np.linalg.det(self.sigma[idx])\n",
    "        #mu_i = mu(X, y, idx)\n",
    "        Pxi = (1/((2*np.pi)**(m/2))) \\\n",
    "                *(1/(det_sigma**0.5)) \\\n",
    "                * np.exp(- 0.5*np.sum(((X-self.mu[idx])@sigma_inv)*(X-self.mu[idx]), axis=1))\n",
    "    #     Pxi = np.log(1) \\\n",
    "    #             - np.log((2*np.pi)**(m/2)) \\\n",
    "    #             - np.log(np.sqrt(det_sigma)) \\\n",
    "    #             - np.sum(((X-mu_i)@sigma_inv)*(X-mu_i), axis=1)\n",
    "        return Pxi\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Computes mean, covariance and proabilities of y (phi)\"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.mu = self.compute_mu(X, y)\n",
    "        self.sigma = self.compute_sigma(X, y)\n",
    "        self.phi = self.compute_phi(y)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Computes the probability of example belonging to that class\"\"\"\n",
    "        n = len(X)\n",
    "        Pyi = np.zeros((n, len(self.classes)))\n",
    "        \n",
    "        for idx in range(len(self.classes)):\n",
    "            #print(self.compute_Pxyi(X, idx))\n",
    "            py_i = self.compute_Pxyi(X, idx) * self.phi[idx]\n",
    "            Pyi[:, idx] = py_i\n",
    "        return Pyi\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "    \n",
    "    def generate_data(self, class_id, num_samples=1):\n",
    "        \"\"\"Generates new unseen dataset from a normal distribution\n",
    "            given the mean of class and covariance\n",
    "        \"\"\"\n",
    "        mean = self.mu[class_id]\n",
    "        cov = self.sigma[class_id]\n",
    "        return np.random.multivariate_normal(mean, cov, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDA = GaussianDiscAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = GDA.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 2, 0, 0, 1, 1, 0, 2, 1, 2, 1, 0, 1, 0, 0, 2, 2, 2,\n",
       "       1, 2, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 0.1947],\n",
       "       [0.    , 0.    , 0.1722],\n",
       "       [0.    , 0.    , 0.2566],\n",
       "       [0.    , 0.0373, 0.    ],\n",
       "       [0.    , 0.0713, 0.0014]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDA.predict_proba(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = GDA.generate_data(class_id=1, num_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.4804, 2.3352, 3.743 , 1.1628],\n",
       "       [5.9854, 2.5037, 3.9809, 0.9537],\n",
       "       [6.0278, 2.6524, 4.093 , 1.1597],\n",
       "       [5.8079, 3.3356, 4.0447, 1.4817],\n",
       "       [6.3876, 2.8588, 4.4784, 1.5099],\n",
       "       [6.3737, 2.5166, 5.1192, 1.3362],\n",
       "       [5.5887, 2.4597, 4.0897, 1.516 ],\n",
       "       [7.1906, 2.8857, 5.7244, 1.5987],\n",
       "       [5.4716, 2.0777, 3.3261, 1.0162],\n",
       "       [5.9089, 2.5441, 4.4017, 1.3938],\n",
       "       [5.1635, 3.0062, 4.1002, 1.3691],\n",
       "       [5.7153, 3.189 , 4.4773, 1.4478],\n",
       "       [6.0914, 2.7472, 4.1508, 1.2791],\n",
       "       [5.0018, 1.7628, 3.4163, 0.7081],\n",
       "       [6.3056, 2.6498, 4.2685, 1.346 ],\n",
       "       [5.9816, 3.0611, 4.5905, 1.4894],\n",
       "       [5.8354, 2.5924, 4.1674, 1.3646],\n",
       "       [5.69  , 2.4421, 3.3969, 1.0013],\n",
       "       [4.8994, 2.3724, 3.0546, 0.9266],\n",
       "       [5.3937, 2.7395, 3.7926, 1.0605]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDA.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
