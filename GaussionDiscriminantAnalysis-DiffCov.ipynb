{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with varying covariance $\\Sigma_1 \\neq \\Sigma_2 \\neq \\Sigma_3 ... \\neq \\Sigma_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To reset the printoptions\n",
    "# np.set_printoptions(edgeitems=3,infstr='inf',linewidth=75, nanstr='nan', precision=8,suppress=False, threshold=1000, formatter=None)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "#np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For multi-class label y ={0, 1, 2, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "#y=(y>0).astype(int) \n",
    "\n",
    "target_names = list(dataset.target_names)\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (38, 4), (112,), (38,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscAnalysis: \n",
    "    def compute_phi(self, y):\n",
    "        n = len(y)\n",
    "        phi = dict()\n",
    "        for idx in range(len(self.classes)):\n",
    "            phi[idx] = (1/n) * np.sum(y==idx)\n",
    "        return phi\n",
    "    \n",
    "    def compute_mu(self, X, y):\n",
    "        mu_dict = dict()\n",
    "        for idx in range(len(self.classes)):\n",
    "            # Add mu for each class\n",
    "            mu_dict[idx] = np.sum(X[y==idx], axis=0)/ np.sum(y==idx)\n",
    "        return mu_dict\n",
    "\n",
    "    def compute_sigma(self, X, y):\n",
    "        sigma_dict = dict()\n",
    "        #n = len(X)\n",
    "        #y = y.reshape(-1,1)\n",
    "        Xmu = X.copy()\n",
    "        for idx in range(len(self.classes)):\n",
    "            n = np.sum(y==idx)\n",
    "            Xmu_i = Xmu[y==idx] - self.mu[idx]\n",
    "            sigma = (1/n) * Xmu_i.T@Xmu_i\n",
    "            sigma_dict[idx] = sigma\n",
    "        return sigma_dict\n",
    "    \n",
    "    \n",
    "    def compute_Pxyi(self, X, idx):\n",
    "        \"\"\"Probability of X given y\"\"\"\n",
    "        m = X.shape[1]\n",
    "        sigma_inv = np.linalg.inv(self.sigma[idx])\n",
    "        det_sigma = np.linalg.det(self.sigma[idx])\n",
    "        #mu_i = mu(X, y, idx)\n",
    "        Pxi = (1/((2*np.pi)**(m/2))) \\\n",
    "                *(1/(det_sigma**0.5)) \\\n",
    "                * np.exp(- 0.5*np.sum(((X-self.mu[idx])@sigma_inv)*(X-self.mu[idx]), axis=1))\n",
    "    #     Pxi = np.log(1) \\\n",
    "    #             - np.log((2*np.pi)**(m/2)) \\\n",
    "    #             - np.log(np.sqrt(det_sigma)) \\\n",
    "    #             - np.sum(((X-mu_i)@sigma_inv)*(X-mu_i), axis=1)\n",
    "        return Pxi\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Computes mean, covariance and proabilities of y (phi)\"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.mu = self.compute_mu(X, y)\n",
    "        self.sigma = self.compute_sigma(X, y)\n",
    "        self.phi = self.compute_phi(y)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Computes the probability of example belonging to that class\"\"\"\n",
    "        n = len(X)\n",
    "        Pyi = np.zeros((n, len(self.classes)))\n",
    "        \n",
    "        for idx in range(len(self.classes)):\n",
    "            #print(self.compute_Pxyi(X, idx))\n",
    "            py_i = self.compute_Pxyi(X, idx) * self.phi[idx]\n",
    "            Pyi[:, idx] = py_i\n",
    "        return Pyi\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "    \n",
    "    def generate_data(self, class_id, num_samples=1):\n",
    "        \"\"\"Generates new unseen dataset from a normal distribution\n",
    "            given the mean of class and covariance\n",
    "        \"\"\"\n",
    "        mean = self.mu[class_id]\n",
    "        cov = self.sigma[class_id]\n",
    "        return np.random.multivariate_normal(mean, cov, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDA = GaussianDiscAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = GDA.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 2, 0, 0, 1, 1, 0, 2, 1, 2, 1, 0, 1, 0, 0, 2, 2, 2,\n",
       "       1, 2, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 0.1947],\n",
       "       [0.    , 0.    , 0.1722],\n",
       "       [0.    , 0.    , 0.2566],\n",
       "       [0.    , 0.0373, 0.    ],\n",
       "       [0.    , 0.0713, 0.0014]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDA.predict_proba(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = GDA.generate_data(class_id=1, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.9675, 2.5222, 4.6476, 1.3642],\n",
       "       [5.1838, 2.3462, 3.9423, 0.9555],\n",
       "       [5.9963, 2.9849, 4.738 , 1.3645],\n",
       "       [5.5439, 2.4985, 3.7781, 1.1449],\n",
       "       [5.4531, 3.1839, 3.8739, 1.4079],\n",
       "       [5.8617, 2.9757, 4.0662, 1.2893],\n",
       "       [5.5628, 2.7596, 4.7163, 1.435 ],\n",
       "       [5.7966, 3.1488, 4.6963, 1.6949],\n",
       "       [5.6333, 2.4279, 4.3005, 1.2556],\n",
       "       [5.6835, 2.2771, 4.1266, 1.2477],\n",
       "       [6.151 , 2.8524, 4.3203, 1.3174],\n",
       "       [5.8238, 2.7191, 4.3683, 1.3531],\n",
       "       [5.4265, 2.3532, 3.6663, 1.1042],\n",
       "       [5.7894, 2.859 , 4.1452, 1.3298],\n",
       "       [5.5581, 2.8484, 3.9068, 1.5076],\n",
       "       [6.3435, 3.1905, 4.535 , 1.4166],\n",
       "       [6.1199, 2.3312, 4.5212, 1.2021],\n",
       "       [6.4661, 2.897 , 5.3044, 1.5201],\n",
       "       [5.8467, 3.1927, 4.2493, 1.5801],\n",
       "       [5.8982, 2.6503, 5.045 , 1.4258],\n",
       "       [6.01  , 2.9193, 4.4122, 1.4452],\n",
       "       [6.3367, 2.8945, 5.0821, 1.8343],\n",
       "       [6.5146, 3.3664, 4.6055, 1.6125],\n",
       "       [5.1452, 2.1495, 3.3473, 1.1171],\n",
       "       [5.5162, 2.7953, 3.59  , 1.1207],\n",
       "       [5.1543, 2.2235, 3.5593, 1.0479],\n",
       "       [6.5844, 3.007 , 4.4666, 1.4281],\n",
       "       [6.6832, 2.683 , 5.1559, 1.5405],\n",
       "       [5.241 , 2.3436, 2.6817, 0.7894],\n",
       "       [5.8986, 2.5968, 3.9147, 1.2294],\n",
       "       [5.7771, 2.9037, 4.1217, 1.2937],\n",
       "       [6.3101, 2.9484, 4.531 , 1.4266],\n",
       "       [6.3489, 2.8274, 4.6094, 1.4279],\n",
       "       [6.2061, 2.9937, 4.1181, 1.2918],\n",
       "       [6.3324, 3.2096, 5.0655, 1.6806],\n",
       "       [6.0145, 2.9688, 4.7821, 1.3872],\n",
       "       [5.2725, 2.68  , 4.5497, 1.5115],\n",
       "       [5.2068, 2.2733, 3.1004, 1.0337],\n",
       "       [5.5507, 3.1704, 3.8994, 1.4455],\n",
       "       [5.3518, 2.6074, 3.8686, 1.1729],\n",
       "       [5.8007, 3.0047, 4.5634, 1.3019],\n",
       "       [5.7682, 2.8454, 3.9479, 1.2261],\n",
       "       [5.9203, 2.7866, 4.0207, 1.4274],\n",
       "       [5.3278, 2.5359, 3.9651, 1.3228],\n",
       "       [6.6555, 2.7849, 4.7246, 1.339 ],\n",
       "       [5.5563, 2.5541, 4.1744, 1.3342],\n",
       "       [5.8698, 2.5247, 4.0915, 1.3207],\n",
       "       [5.4826, 2.4894, 3.9653, 1.0898],\n",
       "       [5.4524, 2.4787, 4.085 , 1.2497],\n",
       "       [5.9842, 3.0807, 4.5487, 1.4116],\n",
       "       [6.3779, 2.8639, 4.3551, 1.435 ],\n",
       "       [5.3483, 2.8811, 3.9267, 1.1914],\n",
       "       [6.6384, 2.8248, 4.0878, 1.4008],\n",
       "       [5.6509, 2.6666, 3.7932, 0.9335],\n",
       "       [5.356 , 2.6489, 4.1385, 1.4104],\n",
       "       [5.9582, 2.5649, 4.1221, 1.2387],\n",
       "       [6.3341, 2.7627, 4.6182, 1.3999],\n",
       "       [5.3733, 2.4773, 3.4884, 0.8505],\n",
       "       [5.8932, 2.4136, 3.8438, 1.0739],\n",
       "       [5.4555, 2.5418, 4.2066, 1.2219],\n",
       "       [5.7166, 2.2926, 3.8748, 1.3471],\n",
       "       [5.2732, 2.2736, 3.0224, 0.9769],\n",
       "       [5.76  , 2.4736, 4.3789, 1.3454],\n",
       "       [6.1224, 2.8562, 4.285 , 1.3311],\n",
       "       [5.2126, 2.5452, 3.2073, 0.952 ],\n",
       "       [6.144 , 2.8696, 4.0877, 1.5252],\n",
       "       [5.7106, 2.8644, 4.79  , 1.4487],\n",
       "       [5.6964, 2.5892, 4.0652, 1.2427],\n",
       "       [5.5792, 2.8732, 4.149 , 1.1504],\n",
       "       [5.7862, 2.7668, 3.9493, 1.1874],\n",
       "       [6.1444, 2.7342, 4.3041, 1.3841],\n",
       "       [5.8567, 2.6561, 3.767 , 1.1947],\n",
       "       [5.9998, 2.645 , 4.3458, 1.3576],\n",
       "       [5.6362, 2.8723, 3.8409, 1.3327],\n",
       "       [5.7503, 3.0398, 3.6633, 1.3573],\n",
       "       [6.1192, 2.801 , 4.8674, 1.6594],\n",
       "       [6.0842, 2.4354, 3.9422, 1.0929],\n",
       "       [5.8693, 2.7458, 4.763 , 1.4618],\n",
       "       [5.6881, 2.8262, 4.4408, 1.4463],\n",
       "       [5.7237, 2.7097, 4.5888, 1.4426],\n",
       "       [5.8711, 2.6479, 4.0447, 1.2905],\n",
       "       [5.8081, 2.7364, 4.4444, 1.4769],\n",
       "       [5.7327, 2.1278, 4.0827, 1.0431],\n",
       "       [5.3649, 2.0099, 3.5334, 0.9468],\n",
       "       [5.5984, 2.6896, 4.4597, 1.4465],\n",
       "       [5.9611, 2.6394, 4.6057, 1.2509],\n",
       "       [6.3638, 2.8784, 4.9986, 1.4151],\n",
       "       [6.1404, 2.7041, 3.9722, 1.2011],\n",
       "       [5.6546, 2.1694, 3.7226, 0.8303],\n",
       "       [5.6845, 2.619 , 4.177 , 1.1835],\n",
       "       [6.1207, 2.7533, 4.1017, 1.1819],\n",
       "       [5.619 , 2.518 , 3.7735, 1.21  ],\n",
       "       [5.5083, 2.5833, 4.0819, 1.4274],\n",
       "       [5.7224, 2.4427, 5.1613, 1.4647],\n",
       "       [5.8586, 2.3913, 3.6774, 1.1959],\n",
       "       [6.2724, 2.8407, 4.8112, 1.2715],\n",
       "       [5.3886, 2.7724, 4.0468, 1.2229],\n",
       "       [6.4187, 2.6792, 4.5854, 1.2666],\n",
       "       [6.0475, 2.7623, 4.3954, 1.437 ],\n",
       "       [5.8141, 2.9218, 4.3617, 1.4375]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDA.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
