{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117570</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.117570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>-0.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.871754</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.817941</td>\n",
       "      <td>-0.366126</td>\n",
       "      <td>0.962865</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.000000 -0.117570  0.871754  0.817941\n",
       "1 -0.117570  1.000000 -0.428440 -0.366126\n",
       "2  0.871754 -0.428440  1.000000  0.962865\n",
       "3  0.817941 -0.366126  0.962865  1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlated dataset can make covariance matrix ill-conditioned\n",
    "pd.DataFrame(X).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's perform PCA to remove linear dependence.\n",
    "dr = PCA(3)\n",
    "dr.fit(X)\n",
    "X_new = dr.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92461872 0.05306648 0.01710261]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.366725e-15</td>\n",
       "      <td>-8.603643e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.366725e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.507649e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.603643e-16</td>\n",
       "      <td>-1.507649e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2\n",
       "0  1.000000e+00  1.366725e-15 -8.603643e-16\n",
       "1  1.366725e-15  1.000000e+00 -1.507649e-16\n",
       "2 -8.603643e-16 -1.507649e-16  1.000000e+00"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dr.explained_variance_ratio_)\n",
    "pd.DataFrame(X_new).corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2, 3],\n",
    "              [1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureModel:\n",
    "    def __init__(self,\n",
    "                 num_clusters: int = 1,\n",
    "                 tolerance: float = 1e-5,\n",
    "                 num_iters: int = 10,\n",
    "                 ):\n",
    "        self.num_clusters = num_clusters\n",
    "        self.tolerance = tolerance\n",
    "        self.num_iters = num_iters\n",
    "        self.X = None\n",
    "    \n",
    "    def gaussian(self, mu, cov):\n",
    "        n, d = self.X.shape\n",
    "        diff = (self.X - mu).T\n",
    "        gauss = np.diagonal(1 / ((2 * np.pi) ** (n / 2) * np.linalg.det(cov) ** 0.5) * np.exp(-0.5 * np.dot(np.dot(diff.T, np.linalg.inv(cov)), diff))).reshape(-1, 1)\n",
    "        return gauss.squeeze()\n",
    "\n",
    "    def initial_means_covs(self):\n",
    "        n, d = self.X.shape\n",
    "        # Mean\n",
    "        random_idx = np.random.permutation(n)\n",
    "        selected_index = random_idx[0:self.num_clusters]\n",
    "        Xmean_init = self.X[selected_index]\n",
    "        # Covs\n",
    "        covs = np.zeros((self.num_clusters, d, d))\n",
    "        for cluster in range(self.num_clusters):\n",
    "            covs[cluster] = self.Xcov\n",
    "        return Xmean_init, self.clip_cov(covs)\n",
    "    \n",
    "    def clip_cov(self, x: np.ndarray):\n",
    "        d = x.shape[1]\n",
    "        return x + np.eye(d, d)\n",
    "    \n",
    "    def compute_Xmean_Xcov(self):\n",
    "        n = self.X.shape[0]\n",
    "        Xmean = np.mean(self.X, axis=0)\n",
    "        Xcentred = self.X - Xmean\n",
    "        Xcov = (1/n) * (Xcentred.T@Xcentred)\n",
    "        print(Xcov)\n",
    "        return Xmean, self.clip_cov(Xcov)\n",
    "    \n",
    "    def initialize_phis(self, num_clusters):\n",
    "        \"\"\" Set all component distribution prior estimates \n",
    "        to the uniform distribution\n",
    "        \"\"\"\n",
    "        return np.array([1/num_clusters for _ in range(num_clusters)])\n",
    "    \n",
    "    def initialize_cluster(self):\n",
    "        n = X.shape[0]\n",
    "        cluster_w = np.ones((n, self.num_clusters)) * 1/self.num_clusters\n",
    "        return cluster_w\n",
    "    \n",
    "    def multivariate_pdf(self, cluster: int):\n",
    "        var = multivariate_normal(mean=self.means[cluster],\n",
    "                                  cov=self.covs[cluster],\n",
    "                                  seed=42,\n",
    "                                 )\n",
    "        return var.pdf(self.X)\n",
    "    \n",
    "    def compute_pXi_Clust_i(self):\n",
    "        for cluster in range(self.num_clusters):\n",
    "            self.pXi_Clust_i[:, cluster] = self.gaussian(self.means[cluster],\n",
    "                                                         self.covs[cluster])\n",
    "            # self.multivariate_pdf(cluster)\n",
    "        return None\n",
    "            \n",
    "    def compute_SigmaPXi_Zi_n_phi(self):\n",
    "        return np.sum(self.pXi_Clust_i * self.phis, axis=1)\n",
    "    \n",
    "    def compute_phis(self) -> None:\n",
    "        self.phis = np.mean(self.cluster_weights, axis=0)\n",
    "        return None\n",
    "        \n",
    "    def compute_means(self) -> None:\n",
    "        for cluster in range(self.num_clusters): \n",
    "            self.means[cluster] = np.sum(self.X * self.cluster_weights[:, cluster].reshape(-1, 1)) \\\n",
    "                                / np.sum(self.cluster_weights[:, cluster])\n",
    "        return None\n",
    "#     def comp_conv(self):\n",
    "#         for j in range(self.X.shape[0]):\n",
    "#             diff = (self.X[j] - mu_k).reshape(-1, 1)\n",
    "#             cov_k += gamma_nk[j] * np.dot(diff, diff.T)\n",
    "            \n",
    "#         cov_k /= N_k\n",
    "    def compute_covs(self) -> None:\n",
    "        d = self.X.shape[1]\n",
    "        for cluster in range(self.num_clusters):\n",
    "            mean_ = self.means[cluster]\n",
    "            Xcentred = self.X - mean_\n",
    "            Xcov = (Xcentred.T@(self.cluster_weights[:, cluster].reshape(-1, 1)*Xcentred))\n",
    "            self.covs[cluster] = Xcov + np.eye(d, d) # self.tolerance * np.eye(d, d)\n",
    "            print(self.covs[cluster])\n",
    "        return None\n",
    "    \n",
    "    def compute_likelihood(self) -> float:\n",
    "        l = self.likelihood + 0.1\n",
    "        return l\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame):\n",
    "        n, d = X.shape\n",
    "        self.X = X.values.copy()\n",
    "        self.Xmean, self.Xcov = self.compute_Xmean_Xcov()\n",
    "        \n",
    "        # Initialize mean and covariance randomly\n",
    "        self.means, self.covs = self.initial_means_covs()        \n",
    "        \n",
    "        # Initialize clusters\n",
    "        self.cluster_weights = self.initialize_cluster()\n",
    "        self.phis = self.initialize_phis(self.num_clusters)\n",
    "        \n",
    "        # Probability distributions\n",
    "        self.pXi_Clust_i = np.zeros((n, self.num_clusters))\n",
    "        self.Sigma_PXi_Zi_n_phi = np.zeros(n)\n",
    "        \n",
    "        iter = 0\n",
    "        mean_norm = 1\n",
    "        self.prev_likelihood = 0\n",
    "        self.likelihood = 0\n",
    "        \n",
    "#         while (iter < self.num_iters) or \\\n",
    "#               (np.linalg.norm(self.prev_likelihood - self.likelihood) <= self.tolerance):\n",
    "        for i in range(2):\n",
    "            # Perform Expectation(E) step\n",
    "            # Compute probability of data given the cluster\n",
    "            self.compute_pXi_Clust_i()\n",
    "            self.compute_SigmaPXi_Zi_n_phi()\n",
    "            # Compute probability of cluster           \n",
    "            for cluster in range(self.num_clusters):\n",
    "                #print(self.pXi_Clust_i)\n",
    "                #print(self.Sigma_PXi_Zi_n_phi.shape)\n",
    "                #print('phis:', self.phis[cluster])\n",
    "                self.cluster_weights[:, cluster] = self.pXi_Clust_i[:, cluster] \\\n",
    "                                                 * self.phis[cluster] \\\n",
    "                                                 / self.Sigma_PXi_Zi_n_phi\n",
    "            #print(self.cluster_weights)\n",
    "            \n",
    "            # Perform Maximization(M) Step\n",
    "            self.compute_phis()\n",
    "            self.compute_means()\n",
    "            \n",
    "            self.compute_covs()\n",
    "            \n",
    "            # TODO: compute log-likelihood\n",
    "            self.likelihood = self.compute_likelihood()\n",
    "            print(f'Log-likelihood for this {iter} iteration is {self.likelihood}')\n",
    "            self.prev_likelihood = self.likelihood\n",
    "                                    \n",
    "            iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.20005343e+00  1.37519625e-15 -4.91458726e-16]\n",
      " [ 1.37519625e-15  2.41052943e-01 -2.06316445e-17]\n",
      " [-4.91458726e-16 -2.06316445e-17  7.76881034e-02]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Log-likelihood for this 0 iteration is 0.1\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Log-likelihood for this 1 iteration is 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:131: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixtureModel(num_clusters=3)\n",
    "gmm.fit(pd.DataFrame(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "var = multivariate_normal(mean=[0,0], cov=[[1,0],[0,1]], seed=42)\n",
    "var.pdf([[0.0,0.0],\n",
    "         [0.0, 0.0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
